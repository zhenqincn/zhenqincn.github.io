<!DOCTYPE html>
<html lang="en">
<!-- Template: https://github.com/luost26/academic-homepage -->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Publications - Zhen Qin</title>
    <link rel="icon" href="/assets/images/favicon.png" type="image/x-icon" />
    <link rel="shortcut icon" href="/assets/images/favicon.png" type="image/x-icon" />
    <!-- Stylesheets -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.6.0/css/bootstrap.min.css" integrity="sha512-P5MgMn1jBN01asBgU0z60Qk4QxiXo86+wlFahKrsQf37c9cro517WzVSPPV1tDKzhku2iJ2FVgL67wG03SGnNA==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha512-DTOQO9RWCH3ppGqcWaEA1BIZOC6xxalwEsw9c2QQeAIftl+Vegovlnee1c9QX4TctnWMn13TZye+giMm8e2LwA==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.1/css/academicons.min.css" integrity="sha512-b1ASx0WHgVFL5ZQhTgiPWX+68KjS38Jk87jg7pe+qC7q9YkEtFq0z7xCglv7qGIs/68d3mAp+StfC8WKC5SSAg==" crossorigin="anonymous" />
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,300;0,400;0,700;0,900;1,300;1,400;1,700;1,900&family=Raleway:ital,wght@0,300;0,400;0,500;1,300;1,400;1,500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.css" integrity="sha384-nB0miv6/jRmo5UMMR1wu3Gz6NLsoTkbqJghGIsx//Rlm+ZU03BU6SQNC66uf4l5+" crossorigin="anonymous">
    <link rel="stylesheet" href="/assets/css/global.css">
</head>
<body class="bg-light" data-spy="scroll" data-target="#navbar-year" data-offset="100">
    <nav class="navbar navbar-expand-sm navbar-light bg-light fixed-top mb-5 shadow-sm">
    <div class="container-lg">
        <a class="navbar-brand"><strong>Zhen Qin</strong></a>
        <button class="navbar-toggler" style="font-size: 1em; padding: 0.5em;" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
            <i class="fas fa-map"></i> Menu
        </button>

        <div class="collapse navbar-collapse" id="navbarResponsive">
            <ul class="navbar-nav ml-auto">
                
                <li class="nav-item ">
                    <a class="nav-link" href="/">Home</a>
                </li>
                
                <li class="nav-item active">
                    <a class="nav-link" href="/publications">Publications</a>
                </li>
                
            </ul>
        </div>
    </div>
</nav>

    <div class="container-lg">
        

<div class="row">
    <div class="col-12 col-lg-10">
        
        
        <h2 class="pt-4" id="year-2025">2025</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-sm">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2025-conf-MM-SeMi.svg" alt="SeMi: When Imbalanced Semi-Supervised Learning Meets Mining Hard Examples" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">SeMi: When Imbalanced Semi-Supervised Learning Meets Mining Hard Examples</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Yin Wang, </span><span class="text-body">
            Zixuan Wang, </span><span class="text-body">
            Hao Lu, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin<sup>*</sup></strong></a>, <span class="text-body">
            Hailiang Zhao, </span><span class="text-body">
            Guanjie Cheng, </span><span class="text-body">
            Ge Su, </span><span class="text-body">
            Li Kuang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=KUkpv6oAAAAJ">Mengchu Zhou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>ACM International Conference on Multimedia (ACM MM)</i> 2025 </p>
            <p class="mt-0 mb-0 small text-muted">Semi-Supervised Learning (SSL) can leverage abundant unlabeled data to boost model performance. However, the class-imbalanced data distribution in real-world scenarios poses great challenges to SSL, resulting in performance degradation. Existing class-imbalanced semi-supervised learning (CISSL) methods mainly focus on rebalancing datasets but ignore the potential of using hard examples to enhance performance, making it difficult to fully harness the power of unlabeled data even with sophisticated algorithms. To address this issue, we propose a method that enhances the performance of Imbalanced Semi-Supervised Learning by Mining Hard Examples (SeMi). This method distinguishes the entropy differences among logits of hard and easy examples, thereby identifying hard examples and increasing the utility of unlabeled data, better addressing the imbalance problem in CISSL. In addition, we maintain a class-balanced memory bank with confidence decay for storing high-confidence embeddings to enhance the pseudo-labels' reliability. Although our method is simple, it is effective and seamlessly integrates with existing approaches. We perform comprehensive experiments on standard CISSL benchmarks and experimentally demonstrate that our proposed SeMi outperforms existing state-of-the-art methods on multiple benchmarks, especially in reversed scenarios, where our best result shows approximately a 54.8\% improvement over the baseline methods.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2501.06004">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray rounded-top  lazy" data-src="/assets/images/covers/2025-conf-MM-SeMi.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">SeMi: When Imbalanced Semi-Supervised Learning Meets Mining Hard Examples</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Yin Wang, </span><span class="text-body">
            Zixuan Wang, </span><span class="text-body">
            Hao Lu, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin<sup>*</sup></strong></a>, <span class="text-body">
            Hailiang Zhao, </span><span class="text-body">
            Guanjie Cheng, </span><span class="text-body">
            Ge Su, </span><span class="text-body">
            Li Kuang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=KUkpv6oAAAAJ">Mengchu Zhou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>ACM International Conference on Multimedia (ACM MM)</i> 2025 </p>
                <p class="mt-0 mb-0 small text-muted">Semi-Supervised Learning (SSL) can leverage abundant unlabeled data to boost model performance. However, the class-imbalanced data distribution in real-world scenarios poses great challenges to SSL, resulting in performance degradation. Existing class-imbalanced semi-supervised learning (CISSL) methods mainly focus on rebalancing datasets but ignore the potential of using hard examples to enhance performance, making it difficult to fully harness the power of unlabeled data even with sophisticated algorithms. To address this issue, we propose a method that enhances the performance of Imbalanced Semi-Supervised Learning by Mining Hard Examples (SeMi). This method distinguishes the entropy differences among logits of hard and easy examples, thereby identifying hard examples and increasing the utility of unlabeled data, better addressing the imbalance problem in CISSL. In addition, we maintain a class-balanced memory bank with confidence decay for storing high-confidence embeddings to enhance the pseudo-labels' reliability. Although our method is simple, it is effective and seamlessly integrates with existing approaches. We perform comprehensive experiments on standard CISSL benchmarks and experimentally demonstrate that our proposed SeMi outperforms existing state-of-the-art methods on multiple benchmarks, especially in reversed scenarios, where our best result shows approximately a 54.8\% improvement over the baseline methods.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2501.06004">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2025-jnl-TPAMI.png" alt="The Synergy Between Data and Multi-Modal Large Language Models: A Survey From Co-Development Perspective" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">The Synergy Between Data and Multi-Modal Large Language Models: A Survey From Co-Development Perspective</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin†</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=1GdfinUAAAAJ">Daoyuan Chen†</a>, <span class="text-body">
            Wenhao Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=0c5is-gAAAAJ">Liuyi Yao</a>, <span class="text-body">
            Yilun Huang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=AjYkTi8AAAAJ">Bolin Ding</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=CCPBcdYAAAAJ">Yaliang Li<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(† <i> equal contribution</i>, <sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i> 2025 </p>
            <p class="mt-0 mb-0 small text-muted">Recent years have witnessed the rapid development of large language models (LLMs). Mmodal LLMs (MLLMs) extend modality from text to various domains, attracting widespread attention due to their diverse application scenarios. As LLMs and MLLMs rely on vast amounts of model parameters and data to achieve emergent capabilities, the importance of data is gaining increasing recognition. Reviewing recent data-driven works for MLLMs, we find that the development of models and data is not two separate paths but rather interconnected. Vaster and higher-quality data improve MLLM performance, while MLLMs, in turn, facilitate the development of data. The co-development of modal data and MLLMs requires a clear view of 1) at which development stages of MLLMs specific data-centric approaches can be employed to enhance certain MLLM capabilities, and 2) how MLLMs, using these capabilities, can contribute to mmodal data in specific roles. To promote data-model co-development for MLLM communities, we systematically review existing works on MLLMs from the data-model co-development perspective.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://ieeexplore.ieee.org/document/11027559">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md">[Project]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2025-jnl-TPAMI.png">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">The Synergy Between Data and Multi-Modal Large Language Models: A Survey From Co-Development Perspective</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin†</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=1GdfinUAAAAJ">Daoyuan Chen†</a>, <span class="text-body">
            Wenhao Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=0c5is-gAAAAJ">Liuyi Yao</a>, <span class="text-body">
            Yilun Huang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=AjYkTi8AAAAJ">Bolin Ding</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=CCPBcdYAAAAJ">Yaliang Li<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(† <i> equal contribution</i>, <sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i> 2025 </p>
                <p class="mt-0 mb-0 small text-muted">Recent years have witnessed the rapid development of large language models (LLMs). Mmodal LLMs (MLLMs) extend modality from text to various domains, attracting widespread attention due to their diverse application scenarios. As LLMs and MLLMs rely on vast amounts of model parameters and data to achieve emergent capabilities, the importance of data is gaining increasing recognition. Reviewing recent data-driven works for MLLMs, we find that the development of models and data is not two separate paths but rather interconnected. Vaster and higher-quality data improve MLLM performance, while MLLMs, in turn, facilitate the development of data. The co-development of modal data and MLLMs requires a clear view of 1) at which development stages of MLLMs specific data-centric approaches can be employed to enhance certain MLLM capabilities, and 2) how MLLMs, using these capabilities, can contribute to mmodal data in specific roles. To promote data-model co-development for MLLM communities, we systematically review existing works on MLLMs from the data-model co-development perspective.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://ieeexplore.ieee.org/document/11027559">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md">[Project]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2025-jnl-TMC.png" alt="Federated Knowledge Distillation using Hierarchical Reinforcement Learning in Resource-Constrained IoT Edge-Cloud Computing Environments" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Federated Knowledge Distillation using Hierarchical Reinforcement Learning in Resource-Constrained IoT Edge-Cloud Computing Environments</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Yishan Chen, </span><span class="text-body">
            Zhiqiang Wang, </span><span class="text-body">
            Huashuai Cai, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng</a></p>
            <p class="mt-0 mb-0 small"><i>IEEE Transactions on Mobile Computing (TMC)</i> 2025 </p>
            <p class="mt-0 mb-0 small text-muted">With the development of Federated Learning (FL) in IoT Edge-Cloud Computing environments, mobile terminals are able to cooperate without the leakage on raw data. However, factors including the terminals' high mobility and the network fluctuations make the cooperator selection during FL training extremely complex. Under the distributed cooperation, traditional FL strategies show certain limitations and cannot always select the available nodes when training, leading to the difficulties in energy and latency optimization. In this paper, we propose a Hierarchical Reinforcement Learning (HRL)-based federated knowledge distillation (HRL-FedKD) framework in which both high-level and low-level controllers utilize the Double Deep Q-Network (DDQN) algorithm. The high-level controller selects the nodes participating in FL training, while the low-level controller determines the number of local training epochs for each node. After training, the global model will be compressed into a lightweight model by knowledge distillation (KD) in deployment while preserving the personalization of local models. The experiments were conducted using Chest X-Ray and Brain Tumor MRI datasets to validate the proposed FL strategy. The results demonstrate that the HRL-FedKD framework can effectively optimize latency and energy consumption in complex state spaces.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11090029">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2025-jnl-TMC.png">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Federated Knowledge Distillation using Hierarchical Reinforcement Learning in Resource-Constrained IoT Edge-Cloud Computing Environments</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Yishan Chen, </span><span class="text-body">
            Zhiqiang Wang, </span><span class="text-body">
            Huashuai Cai, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng</a></p>
                <p class="mt-0 mb-0 small"><i>IEEE Transactions on Mobile Computing (TMC)</i> 2025 </p>
                <p class="mt-0 mb-0 small text-muted">With the development of Federated Learning (FL) in IoT Edge-Cloud Computing environments, mobile terminals are able to cooperate without the leakage on raw data. However, factors including the terminals' high mobility and the network fluctuations make the cooperator selection during FL training extremely complex. Under the distributed cooperation, traditional FL strategies show certain limitations and cannot always select the available nodes when training, leading to the difficulties in energy and latency optimization. In this paper, we propose a Hierarchical Reinforcement Learning (HRL)-based federated knowledge distillation (HRL-FedKD) framework in which both high-level and low-level controllers utilize the Double Deep Q-Network (DDQN) algorithm. The high-level controller selects the nodes participating in FL training, while the low-level controller determines the number of local training epochs for each node. After training, the global model will be compressed into a lightweight model by knowledge distillation (KD) in deployment while preserving the personalization of local models. The experiments were conducted using Chest X-Ray and Brain Tumor MRI datasets to validate the proposed FL strategy. The results demonstrate that the HRL-FedKD framework can effectively optimize latency and energy consumption in complex state spaces.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=11090029">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2025-conf-ACL-FL.svg" alt="Federated Data-Efficient Instruction Tuning for Large Language Models" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Federated Data-Efficient Instruction Tuning for Large Language Models</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=QjehmgkAAAAJ">Zhaomin Wu<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=RogYLKYAAAAJ">Bingsheng He</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng</a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>Annual Meeting of the Association for Computational Linguistics (ACL)</i> 2025 </p>
            <p class="mt-0 mb-0 small text-muted">Instruction tuning helps improve pretrained large language models (LLMs) in terms of the responsiveness to human instructions, which is benefited from diversified instruction data. Federated learning extends the sources of instruction data by exploiting the diversified client-side data, making it increasingly popular for tuning LLMs. Existing approaches of federated LLM tuning typically traverse all local data during local training, bringing excessive computation overhead and posing a risk of overfitting local data. Thus, a federated data-efficient instruction tuning approach, which consumes relatively little data from the entire dataset, is needed. In response, this work introduces an approach of federated data-efficient instruction tuning for LLMs, FedHDS, which utilizes a representative subset of edge-side data, coreset, to tune the LLM. It reduces the redundancy of data samples at both intra-client and inter-client levels through a hierarchical data selection framework performed by jointly selecting a small number of representative data samples for local training without sharing the raw data. Extensive experiments conducted across six scenarios with various LLMs, datasets and data partitions demonstrate that FedHDS significantly reduces the amount of data required for fine-tuning while improving the responsiveness of the instruction-tuned LLMs to unseen tasks.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://aclanthology.org/2025.findings-acl.803">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/zhenqincn/FedHDS">[Code]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2025-conf-ACL-FL.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Federated Data-Efficient Instruction Tuning for Large Language Models</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=QjehmgkAAAAJ">Zhaomin Wu<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=RogYLKYAAAAJ">Bingsheng He</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng</a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>Annual Meeting of the Association for Computational Linguistics (ACL)</i> 2025 </p>
                <p class="mt-0 mb-0 small text-muted">Instruction tuning helps improve pretrained large language models (LLMs) in terms of the responsiveness to human instructions, which is benefited from diversified instruction data. Federated learning extends the sources of instruction data by exploiting the diversified client-side data, making it increasingly popular for tuning LLMs. Existing approaches of federated LLM tuning typically traverse all local data during local training, bringing excessive computation overhead and posing a risk of overfitting local data. Thus, a federated data-efficient instruction tuning approach, which consumes relatively little data from the entire dataset, is needed. In response, this work introduces an approach of federated data-efficient instruction tuning for LLMs, FedHDS, which utilizes a representative subset of edge-side data, coreset, to tune the LLM. It reduces the redundancy of data samples at both intra-client and inter-client levels through a hierarchical data selection framework performed by jointly selecting a small number of representative data samples for local training without sharing the raw data. Extensive experiments conducted across six scenarios with various LLMs, datasets and data partitions demonstrate that FedHDS significantly reduces the amount of data required for fine-tuning while improving the responsiveness of the instruction-tuned LLMs to unseen tasks.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://aclanthology.org/2025.findings-acl.803">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/zhenqincn/FedHDS">[Code]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2025-conf-ACL-ExploraCoder.svg" alt="ExploraCoder: Advancing Code Generation for Multiple Unseen APIs via Planning and Chained Exploration" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">ExploraCoder: Advancing Code Generation for Multiple Unseen APIs via Planning and Chained Exploration</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Yunkun Wang, </span><span class="text-body">
            Yue Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Chen Zhi<sup>*</sup>, </span><span class="text-body">
            Binhua Li, </span><span class="text-body">
            Fei Huang, </span><span class="text-body">
            Yongbin Li<sup>*</sup>, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>Annual Meeting of the Association for Computational Linguistics (ACL)</i> 2025 </p>
            <p class="mt-0 mb-0 small text-muted">Large language models face intrinsic limitations in coding with APIs that are unseen in their training corpora. As libraries continuously evolve, it becomes impractical to exhaustively retrain LLMs with new API knowledge. This limitation hampers LLMs from solving programming problems which require newly introduced or privately maintained libraries. Inspired by exploratory programming paradigm in human behavior, we propose ExploraCoder, a training-free framework that empowers LLMs to invoke multiple unseen APIs in code solution by (1) planning a complex problem into several API invocation subtasks, and (2) experimenting with correct API usage at intermediate steps through a novel chain-of-API-exploration. We conduct evaluation on program synthesizing tasks involving complex API interactions. Experimental results demonstrate that ExploraCoder significantly improves performance for models lacking prior API knowledge, achieving absolute increases of up to 11.99% over retrieval-based approaches and 17.28% over pretraining-based methods in pass@10.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://aclanthology.org/2025.acl-long.887/">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/greenlight2000/ExploraCoder">[Project]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2025-conf-ACL-ExploraCoder.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">ExploraCoder: Advancing Code Generation for Multiple Unseen APIs via Planning and Chained Exploration</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Yunkun Wang, </span><span class="text-body">
            Yue Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Chen Zhi<sup>*</sup>, </span><span class="text-body">
            Binhua Li, </span><span class="text-body">
            Fei Huang, </span><span class="text-body">
            Yongbin Li<sup>*</sup>, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>Annual Meeting of the Association for Computational Linguistics (ACL)</i> 2025 </p>
                <p class="mt-0 mb-0 small text-muted">Large language models face intrinsic limitations in coding with APIs that are unseen in their training corpora. As libraries continuously evolve, it becomes impractical to exhaustively retrain LLMs with new API knowledge. This limitation hampers LLMs from solving programming problems which require newly introduced or privately maintained libraries. Inspired by exploratory programming paradigm in human behavior, we propose ExploraCoder, a training-free framework that empowers LLMs to invoke multiple unseen APIs in code solution by (1) planning a complex problem into several API invocation subtasks, and (2) experimenting with correct API usage at intermediate steps through a novel chain-of-API-exploration. We conduct evaluation on program synthesizing tasks involving complex API interactions. Experimental results demonstrate that ExploraCoder significantly improves performance for models lacking prior API knowledge, achieving absolute increases of up to 11.99% over retrieval-based approaches and 17.28% over pretraining-based methods in pass@10.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://aclanthology.org/2025.acl-long.887/">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/greenlight2000/ExploraCoder">[Project]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2025-arXiv-VFL-Survey.svg" alt="Vertical Federated Learning in Practice: The Good, the Bad, and the Ugly" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Vertical Federated Learning in Practice: The Good, the Bad, and the Ugly</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=QjehmgkAAAAJ">Zhaomin Wu</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Junyi Hou, </span><span class="text-body">
            Haodong Zhao, </span><span class="text-body">
            Qinbin Li, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=RogYLKYAAAAJ">Bingsheng He</a>, <span class="text-body">
            Lixin Fan</span></p>
            <p class="mt-0 mb-0 small"><i>arXiv:2502.08160</i> 2025 </p>
            <p class="mt-0 mb-0 small text-muted">Vertical Federated Learning (VFL) is a privacy-preserving collaborative learning paradigm that enables multiple parties with distinct feature sets to jointly train machine learning models without sharing their raw data. Despite its potential to facilitate cross-organizational collaborations, the deployment of VFL systems in real-world applications remains limited. To investigate the gap between existing VFL research and practical deployment, this survey analyzes the real-world data distributions in potential VFL applications and identifies four key findings that highlight this gap. We propose a novel data-oriented taxonomy of VFL algorithms based on real VFL data distributions. Our comprehensive review of existing VFL algorithms reveals that some common practical VFL scenarios have few or no viable solutions. Based on these observations, we outline key research directions aimed at bridging the gap between current VFL research and real-world applications.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2502.08160">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none  border-gray  rounded-bottom lazy" data-src="/assets/images/covers/2025-arXiv-VFL-Survey.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Vertical Federated Learning in Practice: The Good, the Bad, and the Ugly</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=QjehmgkAAAAJ">Zhaomin Wu</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Junyi Hou, </span><span class="text-body">
            Haodong Zhao, </span><span class="text-body">
            Qinbin Li, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=RogYLKYAAAAJ">Bingsheng He</a>, <span class="text-body">
            Lixin Fan</span></p>
                <p class="mt-0 mb-0 small"><i>arXiv:2502.08160</i> 2025 </p>
                <p class="mt-0 mb-0 small text-muted">Vertical Federated Learning (VFL) is a privacy-preserving collaborative learning paradigm that enables multiple parties with distinct feature sets to jointly train machine learning models without sharing their raw data. Despite its potential to facilitate cross-organizational collaborations, the deployment of VFL systems in real-world applications remains limited. To investigate the gap between existing VFL research and practical deployment, this survey analyzes the real-world data distributions in potential VFL applications and identifies four key findings that highlight this gap. We propose a novel data-oriented taxonomy of VFL algorithms based on real VFL data distributions. Our comprehensive review of existing VFL algorithms reveals that some common practical VFL scenarios have few or no viable solutions. Based on these observations, we outline key research directions aimed at bridging the gap between current VFL research and real-world applications.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2502.08160">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
        
        <h2 class="pt-4" id="year-2024">2024</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-sm">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2024-arXiv-FedAMoLE.svg" alt="Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Yicheng Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin<sup>*</sup></strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=QjehmgkAAAAJ">Zhaomin Wu</a>, <span class="text-body">
            Jian Hou, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng</a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>arXiv:2411.19128</i> 2024 </p>
            <p class="mt-0 mb-0 small text-muted">Large-scale instruction data is essential for aligning pretrained Large Language Models (LLMs) with human instructions, but may contain sensitive information that hinders its public sharing. Federated Learning (FL) enables collaborative fine-tuning of LLMs without accessing raw data. However, existing approaches to federated LLM fine-tuning usually adopt a uniform model architecture, making it hard to fit highly heterogeneous client-side data in varying domains and formats. To address this, we propose FedAMoLE, a lightweight personalized FL framework that enables data-driven heterogeneous model architectures. This framework features a heterogeneous mixture of LoRA experts module for aggregating architecturally heterogeneous models and a reverse selection-based expert assignment strategy that optimizes model architectures based on data distributions. Experiments across five scenarios show that FedAMoLE improves client-side performance by an average of 5.14% compared to existing approaches while maintaining scalability.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://arxiv.org/abs/2411.19128">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray rounded-top  lazy" data-src="/assets/images/covers/2024-arXiv-FedAMoLE.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Personalized Federated Fine-Tuning for LLMs via Data-Driven Heterogeneous Model Architectures</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Yicheng Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin<sup>*</sup></strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=QjehmgkAAAAJ">Zhaomin Wu</a>, <span class="text-body">
            Jian Hou, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng</a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>arXiv:2411.19128</i> 2024 </p>
                <p class="mt-0 mb-0 small text-muted">Large-scale instruction data is essential for aligning pretrained Large Language Models (LLMs) with human instructions, but may contain sensitive information that hinders its public sharing. Federated Learning (FL) enables collaborative fine-tuning of LLMs without accessing raw data. However, existing approaches to federated LLM fine-tuning usually adopt a uniform model architecture, making it hard to fit highly heterogeneous client-side data in varying domains and formats. To address this, we propose FedAMoLE, a lightweight personalized FL framework that enables data-driven heterogeneous model architectures. This framework features a heterogeneous mixture of LoRA experts module for aggregating architecturally heterogeneous models and a reverse selection-based expert assignment strategy that optimizes model architectures based on data distributions. Experiments across five scenarios show that FedAMoLE improves client-side performance by an average of 5.14% compared to existing approaches while maintaining scalability.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://arxiv.org/abs/2411.19128">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2024-conf-ICML.svg" alt="Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=1GdfinUAAAAJ">Daoyuan Chen</a>, <span class="text-body">
            Bingchen Qian, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=AjYkTi8AAAAJ">Bolin Ding</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=CCPBcdYAAAAJ">Yaliang Li<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>International Conference on Machine Learning (ICML)</i> 2024 </p>
            <p class="mt-0 mb-0 small text-muted">Pre-trained large language models (LLMs) require fine-tuning to improve their responsiveness to natural language instructions. Federated learning (FL) offers a way to perform fine-tuning using the abundant data on end devices without compromising data privacy. Most existing federated fine-tuning methods for LLMs rely on parameter-efficient fine-tuning techniques, which may not reach the performance heights possible with full-parameter tuning. However, the communication overhead associated with full-parameter tuning is prohibitively high for both servers and clients. This work introduces FedKSeed, a novel approach that employs zeroth-order optimization (ZOO) with a set of random seeds. It enables federated full-parameter tuning of billion-sized LLMs directly on devices. Our method significantly reduces transmission requirements between the server and clients to just a few scalar gradients and random seeds, amounting to only a few thousand bytes. Building on this, we develop a strategy to assess the significance of ZOO perturbations for FL, allowing for probability-differentiated seed sampling. This prioritizes perturbations that have a greater impact on model accuracy. Experiments across six scenarios with different LLMs, datasets and data partitions demonstrate that our approach outperforms existing federated LLM fine-tuning methods in terms of both communication efficiency and new task generalization.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://proceedings.mlr.press/v235/qin24a.html">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/alibaba/FederatedScope/tree/FedKSeed">[Project]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2024-conf-ICML.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Federated Full-Parameter Tuning of Billion-Sized Language Models with Communication Cost under 18 Kilobytes</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=1GdfinUAAAAJ">Daoyuan Chen</a>, <span class="text-body">
            Bingchen Qian, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=AjYkTi8AAAAJ">Bolin Ding</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=CCPBcdYAAAAJ">Yaliang Li<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>International Conference on Machine Learning (ICML)</i> 2024 </p>
                <p class="mt-0 mb-0 small text-muted">Pre-trained large language models (LLMs) require fine-tuning to improve their responsiveness to natural language instructions. Federated learning (FL) offers a way to perform fine-tuning using the abundant data on end devices without compromising data privacy. Most existing federated fine-tuning methods for LLMs rely on parameter-efficient fine-tuning techniques, which may not reach the performance heights possible with full-parameter tuning. However, the communication overhead associated with full-parameter tuning is prohibitively high for both servers and clients. This work introduces FedKSeed, a novel approach that employs zeroth-order optimization (ZOO) with a set of random seeds. It enables federated full-parameter tuning of billion-sized LLMs directly on devices. Our method significantly reduces transmission requirements between the server and clients to just a few scalar gradients and random seeds, amounting to only a few thousand bytes. Building on this, we develop a strategy to assess the significance of ZOO perturbations for FL, allowing for probability-differentiated seed sampling. This prioritizes perturbations that have a greater impact on model accuracy. Experiments across six scenarios with different LLMs, datasets and data partitions demonstrate that our approach outperforms existing federated LLM fine-tuning methods in terms of both communication efficiency and new task generalization.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://proceedings.mlr.press/v235/qin24a.html">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/alibaba/FederatedScope/tree/FedKSeed">[Project]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2024-jnl-TAAS.png" alt="Adaptive Scheduling of High-Availability Drone Swarms for Congestion Alleviation in Connected Automated Vehicles" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Adaptive Scheduling of High-Availability Drone Swarms for Congestion Alleviation in Connected Automated Vehicles</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Shengye Pang,, </span><span class="text-body">
            Yi Li, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Xinkui Zhao<sup>*</sup>, </span><span class="text-body">
            Jintao Chen, </span><span class="text-body">
            Fan Wang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=0s1A5fwAAAAJ">Jianwei Yin</a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>ACM Transactions on Autonomous and Adaptive Systems (TAAS)</i> 2024 </p>
            <p class="mt-0 mb-0 small text-muted">The Intelligent Transportation System (ITS) serves as a pivotal element within urban networks, offering decision support to users and connected automated vehicles (CAVs) through comprehensive information gathering, sensing, device control, and data processing. Presently, ITS predominantly relies on sensors embedded in fixed infrastructure, notably Roadside Units (RSUs). However, RSUs are confined by coverage limitations and may encounter challenges in prompt emergency responses. On-demand resources, such as drones, present a viable option to supplement these deficiencies effectively. This paper introduces an approach where Software-Defined Networking (SDN) and Mobile Edge Computing (MEC) technologies are integrated to formulate a high-availability drone swarm control and communication infrastructure framework, comprising the cloud layer, edge layer, and device layer. Drones confront limitations in flight duration attributed to battery limitations, posing a challenge in sustaining continuous monitoring of road conditions over extended periods. Effective drone scheduling stands as a promising solution to overcome these constraints. To tackle this issue, we initially utilized Graph WaveNet, a specialized graph neural network structure tailored for spatial-temporal graph modeling, for training a congestion prediction model using real-world dataset inputs. Building upon this, we further propose an algorithm for drone scheduling based on congestion prediction. Our simulation experiments using real-world data demonstrate that, compared to the baseline method, the proposed scheduling algorithm not only yielded superior scheduling gains but also mitigated drone idle rates.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3673905">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2024-jnl-TAAS.png">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Adaptive Scheduling of High-Availability Drone Swarms for Congestion Alleviation in Connected Automated Vehicles</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Shengye Pang,, </span><span class="text-body">
            Yi Li, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Xinkui Zhao<sup>*</sup>, </span><span class="text-body">
            Jintao Chen, </span><span class="text-body">
            Fan Wang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=0s1A5fwAAAAJ">Jianwei Yin</a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>ACM Transactions on Autonomous and Adaptive Systems (TAAS)</i> 2024 </p>
                <p class="mt-0 mb-0 small text-muted">The Intelligent Transportation System (ITS) serves as a pivotal element within urban networks, offering decision support to users and connected automated vehicles (CAVs) through comprehensive information gathering, sensing, device control, and data processing. Presently, ITS predominantly relies on sensors embedded in fixed infrastructure, notably Roadside Units (RSUs). However, RSUs are confined by coverage limitations and may encounter challenges in prompt emergency responses. On-demand resources, such as drones, present a viable option to supplement these deficiencies effectively. This paper introduces an approach where Software-Defined Networking (SDN) and Mobile Edge Computing (MEC) technologies are integrated to formulate a high-availability drone swarm control and communication infrastructure framework, comprising the cloud layer, edge layer, and device layer. Drones confront limitations in flight duration attributed to battery limitations, posing a challenge in sustaining continuous monitoring of road conditions over extended periods. Effective drone scheduling stands as a promising solution to overcome these constraints. To tackle this issue, we initially utilized Graph WaveNet, a specialized graph neural network structure tailored for spatial-temporal graph modeling, for training a congestion prediction model using real-world dataset inputs. Building upon this, we further propose an algorithm for drone scheduling based on congestion prediction. Our simulation experiments using real-world data demonstrate that, compared to the baseline method, the proposed scheduling algorithm not only yielded superior scheduling gains but also mitigated drone idle rates.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3673905">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2024-conf-WWW-anomaly.png" alt="LARA: A Light and Anti-overfitting Retraining Approach for Unsupervised Time Series Anomaly Detection" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">LARA: A Light and Anti-overfitting Retraining Approach for Unsupervised Time Series Anomaly Detection</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Feiyi Chen, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=KUkpv6oAAAAJ">Mengchu Zhou</a>, <span class="text-body">
            Yingying Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>, <span class="text-body">
            Lunting Fan, </span><span class="text-body">
            Guansong Pang, </span><span class="text-body">
            Qingsong Wen</span>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>The Web Conference (WWW)</i> 2024 </p>
            <p class="mt-0 mb-0 small text-muted">Most of current anomaly detection models assume that the normal pattern remains the same all the time. However, the normal patterns of web services can change dramatically and frequently over time. The model trained on old-distribution data becomes outdated and ineffective after such changes. Retraining the whole model whenever the pattern is changed is computationally expensive. Further, at the beginning of normal pattern changes, there is not enough observation data from the new distribution. Retraining a large neural network model with limited data is vulnerable to overfitting. Thus, we propose a Light Anti-overfitting Retraining Approach (LARA) based on deep variational auto-encoders for time series anomaly detection. In LARA we make the following three major contributions: 1) the retraining process is designed as a convex problem such that overfitting is prevented and the retraining process can converge fast; 2) a novel ruminate block is introduced, which can leverage the historical data without the need to store them; 3) we mathematically and experimentally prove that when fine-tuning the latent vector and reconstructed data, the linear formations can achieve the least adjusting errors between the ground truths and the fine-tuned ones. Moreover, we have performed many experiments to verify that retraining LARA with even a limited amount of data from new distribution can achieve competitive performance in comparison with the state-of-the-art anomaly detection models trained with sufficient data. Besides, we verify its light computational overhead.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3589334.3645472">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2024-conf-WWW-anomaly.png">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">LARA: A Light and Anti-overfitting Retraining Approach for Unsupervised Time Series Anomaly Detection</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Feiyi Chen, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=KUkpv6oAAAAJ">Mengchu Zhou</a>, <span class="text-body">
            Yingying Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>, <span class="text-body">
            Lunting Fan, </span><span class="text-body">
            Guansong Pang, </span><span class="text-body">
            Qingsong Wen</span>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>The Web Conference (WWW)</i> 2024 </p>
                <p class="mt-0 mb-0 small text-muted">Most of current anomaly detection models assume that the normal pattern remains the same all the time. However, the normal patterns of web services can change dramatically and frequently over time. The model trained on old-distribution data becomes outdated and ineffective after such changes. Retraining the whole model whenever the pattern is changed is computationally expensive. Further, at the beginning of normal pattern changes, there is not enough observation data from the new distribution. Retraining a large neural network model with limited data is vulnerable to overfitting. Thus, we propose a Light Anti-overfitting Retraining Approach (LARA) based on deep variational auto-encoders for time series anomaly detection. In LARA we make the following three major contributions: 1) the retraining process is designed as a convex problem such that overfitting is prevented and the retraining process can converge fast; 2) a novel ruminate block is introduced, which can leverage the historical data without the need to store them; 3) we mathematically and experimentally prove that when fine-tuning the latent vector and reconstructed data, the linear formations can achieve the least adjusting errors between the ground truths and the fine-tuned ones. Moreover, we have performed many experiments to verify that retraining LARA with even a limited amount of data from new distribution can achieve competitive performance in comparison with the state-of-the-art anomaly detection models trained with sufficient data. Besides, we verify its light computational overhead.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3589334.3645472">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2024-conf-WWW-BlockDFL.svg" alt="BlockDFL: A Blockchain-based Fully Decentralized Peer-to-Peer Federated Learning Framework" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">BlockDFL: A Blockchain-based Fully Decentralized Peer-to-Peer Federated Learning Framework</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37088391525">Xueqiang Yan</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=KUkpv6oAAAAJ">Mengchu Zhou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>The Web Conference (WWW)</i> 2024 <span class="badge badge-pill badge-publication badge-success">Spotlight</span></p>
            <p class="mt-0 mb-0 small text-muted">Federated learning (FL) enables the collaborative training of machine learning models without sharing training data. Traditional FL heavily relies on a trusted centralized server. Although decentralized FL eliminates the dependence on a centralized server, it faces such issues as poisoning attacks and data representation leakage due to insufficient restrictions on the behavior of participants, and heavy communication costs in fully decentralized scenarios, i.e., peer-to-peer (P2P) settings. This work proposes a blockchainbased fully decentralized P2P framework for FL, called BlockDFL. It takes blockchain as the foundation, leveraging the proposed voting mechanism and a two-layer scoring mechanism to coordinate FL among participants without mutual trust, while effectively defending against poisoning attacks. Gradient compression is introduced to lower communication cost and to prevent data from being reconstructed from transmitted model updates. The results of extensive experiments conducted on two real-world datasets exhibit that BlockDFL obtains competitive accuracy compared to centralized FL and can defend against poisoning attacks while achieving efficiency and scalability. Especially when the proportion of malicious participants is as high as 40%, BlockDFL can still preserve the accuracy of FL, outperforming existing fully decentralized P2P FL frameworks based on blockchain.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://dl.acm.org/doi/10.1145/3589334.3645425">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2024-conf-WWW-BlockDFL.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">BlockDFL: A Blockchain-based Fully Decentralized Peer-to-Peer Federated Learning Framework</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37088391525">Xueqiang Yan</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=KUkpv6oAAAAJ">Mengchu Zhou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>The Web Conference (WWW)</i> 2024 <span class="badge badge-pill badge-publication badge-success">Spotlight</span></p>
                <p class="mt-0 mb-0 small text-muted">Federated learning (FL) enables the collaborative training of machine learning models without sharing training data. Traditional FL heavily relies on a trusted centralized server. Although decentralized FL eliminates the dependence on a centralized server, it faces such issues as poisoning attacks and data representation leakage due to insufficient restrictions on the behavior of participants, and heavy communication costs in fully decentralized scenarios, i.e., peer-to-peer (P2P) settings. This work proposes a blockchainbased fully decentralized P2P framework for FL, called BlockDFL. It takes blockchain as the foundation, leveraging the proposed voting mechanism and a two-layer scoring mechanism to coordinate FL among participants without mutual trust, while effectively defending against poisoning attacks. Gradient compression is introduced to lower communication cost and to prevent data from being reconstructed from transmitted model updates. The results of extensive experiments conducted on two real-world datasets exhibit that BlockDFL obtains competitive accuracy compared to centralized FL and can defend against poisoning attacks while achieving efficiency and scalability. Especially when the proportion of malicious participants is as high as 40%, BlockDFL can still preserve the accuracy of FL, outperforming existing fully decentralized P2P FL frameworks based on blockchain.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://dl.acm.org/doi/10.1145/3589334.3645425">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2024-conf-ICDE.png" alt="Learning Multi-Pattern Normalities in the Frequency Domain for Efficient Time Series Anomaly Detection" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Learning Multi-Pattern Normalities in the Frequency Domain for Efficient Time Series Anomaly Detection</h5>
            <p class="mt-0 mb-0 small"><span class="text-body">
            Feiyi Chen, </span><span class="text-body">
            Yingying Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Lunting Fan, </span><span class="text-body">
            Renhe Jiang, </span><span class="text-body">
            Yuxuan Liang, </span><span class="text-body">
            Qingsong Wen, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>International Conference on Data Engineering (ICDE)</i> 2024 </p>
            <p class="mt-0 mb-0 small text-muted">Pre-trained large language models (LLMs) require fine-tuning to improve their responsiveness to natural language instructions. Federated learning (FL) offers a way to perform fine-tuning using the abundant data on end devices without compromising data privacy. Most existing federated fine-tuning methods for LLMs rely on parameter-efficient fine-tuning techniques, which may not reach the performance heights possible with full-parameter tuning. However, the communication overhead associated with full-parameter tuning is prohibitively high for both servers and clients. This work introduces FedKSeed, a novel approach that employs zeroth-order optimization (ZOO) with a set of random seeds. It enables federated full-parameter tuning of billion-sized LLMs directly on devices. Our method significantly reduces transmission requirements between the server and clients to just a few scalar gradients and random seeds, amounting to only a few thousand bytes. Building on this, we develop a strategy to assess the significance of ZOO perturbations for FL, allowing for probability-differentiated seed sampling. This prioritizes perturbations that have a greater impact on model accuracy. Experiments across six scenarios with different LLMs, datasets and data partitions demonstrate that our approach outperforms existing federated LLM fine-tuning methods in terms of both communication efficiency and new task generalization.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10597864">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2024-conf-ICDE.png">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Learning Multi-Pattern Normalities in the Frequency Domain for Efficient Time Series Anomaly Detection</h5>
                <p class="mt-0 mb-0 small"><span class="text-body">
            Feiyi Chen, </span><span class="text-body">
            Yingying Zhang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Lunting Fan, </span><span class="text-body">
            Renhe Jiang, </span><span class="text-body">
            Yuxuan Liang, </span><span class="text-body">
            Qingsong Wen, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>International Conference on Data Engineering (ICDE)</i> 2024 </p>
                <p class="mt-0 mb-0 small text-muted">Pre-trained large language models (LLMs) require fine-tuning to improve their responsiveness to natural language instructions. Federated learning (FL) offers a way to perform fine-tuning using the abundant data on end devices without compromising data privacy. Most existing federated fine-tuning methods for LLMs rely on parameter-efficient fine-tuning techniques, which may not reach the performance heights possible with full-parameter tuning. However, the communication overhead associated with full-parameter tuning is prohibitively high for both servers and clients. This work introduces FedKSeed, a novel approach that employs zeroth-order optimization (ZOO) with a set of random seeds. It enables federated full-parameter tuning of billion-sized LLMs directly on devices. Our method significantly reduces transmission requirements between the server and clients to just a few scalar gradients and random seeds, amounting to only a few thousand bytes. Building on this, we develop a strategy to assess the significance of ZOO perturbations for FL, allowing for probability-differentiated seed sampling. This prioritizes perturbations that have a greater impact on model accuracy. Experiments across six scenarios with different LLMs, datasets and data partitions demonstrate that our approach outperforms existing federated LLM fine-tuning methods in terms of both communication efficiency and new task generalization.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/10597864">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2024-conf-AAAI.svg" alt="Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Feiyi Chen, </span><span class="text-body">
            Chen Zhi, </span><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37088391525">Xueqiang Yan</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>AAAI Conference on Artificial Intelligence (AAAI)</i> 2024 </p>
            <p class="mt-0 mb-0 small text-muted">Existing approaches defend against backdoor attacks in federated learning (FL) mainly through a) mitigating the impact of infected models, or b) excluding infected models. The former negatively impacts model accuracy, while the latter usually relies on globally clear boundaries between benign and infected model updates. However, in reality, model updates can easily become mixed and scattered throughout due to the diverse distributions of local data. This work focuses on excluding infected models in FL. Unlike previous perspectives from a global view, we propose Snowball, a novel anti-backdoor FL framework through bidirectional elections from an individual perspective inspired by one principle deduced by us and two principles in FL and deep learning. It is characterized by a) bottom-up election, where each candidate model update votes to several peer ones such that a few model updates are elected as selectees for aggregation; and b) top-down election, where selectees progressively enlarge themselves through picking up from the candidates. We compare Snowball with state-of-the-art defenses to backdoor attacks in FL on five real-world datasets, demonstrating its superior resistance to backdoor attacks and slight impact on the accuracy of the global model.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/29385">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/zhenqincn/Snowball">[Project]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none  border-gray  rounded-bottom lazy" data-src="/assets/images/covers/2024-conf-AAAI.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Resisting Backdoor Attacks in Federated Learning via Bidirectional Elections and Individual Perspective</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Feiyi Chen, </span><span class="text-body">
            Chen Zhi, </span><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37088391525">Xueqiang Yan</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>AAAI Conference on Artificial Intelligence (AAAI)</i> 2024 </p>
                <p class="mt-0 mb-0 small text-muted">Existing approaches defend against backdoor attacks in federated learning (FL) mainly through a) mitigating the impact of infected models, or b) excluding infected models. The former negatively impacts model accuracy, while the latter usually relies on globally clear boundaries between benign and infected model updates. However, in reality, model updates can easily become mixed and scattered throughout due to the diverse distributions of local data. This work focuses on excluding infected models in FL. Unlike previous perspectives from a global view, we propose Snowball, a novel anti-backdoor FL framework through bidirectional elections from an individual perspective inspired by one principle deduced by us and two principles in FL and deep learning. It is characterized by a) bottom-up election, where each candidate model update votes to several peer ones such that a few model updates are elected as selectees for aggregation; and b) top-down election, where selectees progressively enlarge themselves through picking up from the candidates. We compare Snowball with state-of-the-art defenses to backdoor attacks in FL on five real-world datasets, demonstrating its superior resistance to backdoor attacks and slight impact on the accuracy of the global model.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://ojs.aaai.org/index.php/AAAI/article/view/29385">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/zhenqincn/Snowball">[Project]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
        
        <h2 class="pt-4" id="year-2023">2023</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-sm">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2023-conf-KDD-FedAPEN.svg" alt="FedAPEN: Personalized Cross-silo Federated Learning with Adaptability to Statistical Heterogeneity" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">FedAPEN: Personalized Cross-silo Federated Learning with Adaptability to Statistical Heterogeneity</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37089179203">Mingyu Zhao</a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37088391525">Xueqiang Yan</a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</i> 2023 </p>
            <p class="mt-0 mb-0 small text-muted">In cross-silo federated learning (FL), the data among clients are usually statistically heterogeneous (aka not independent and identically distributed, non-IID) due to diversified data sources, lowering the accuracy of FL. Although many personalized FL (PFL) approaches have been proposed to address this issue, they are only suitable for data with specific degrees of statistical heterogeneity. In the real world, the heterogeneity of data among clients is often immeasurable due to privacy concern, making the targeted selection of PFL approaches difficult. Besides, in cross-silo FL, clients are usually from different organizations, tending to hold architecturally different private models. In this work, we propose a novel FL framework, FedAPEN, which combines mutual learning and ensemble learning to take the advantages of private and shared global models while allowing heterogeneous models. Within FedAPEN, we propose two mechanisms to coordinate and promote model ensemble such that FedAPEN achieves excellent accuracy on various data distributions without prior knowledge of data heterogeneity, and thus, obtains the adaptability to data heterogeneity. We conduct extensive experiments on four real-world datasets, including: 1) Fashion MNIST, CIFAR-10, and CIFAR-100, each with ten different types and degrees of label distribution skew; and 2) eICU with feature distribution skew. The experiments demonstrate that FedAPEN almost obtains superior accuracy on data with varying types and degrees of heterogeneity compared with baselines.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3580305.3599344">[Paper]</a>
                
                
                
                <a target="_blank" href="https://github.com/zhenqincn/FedAPEN">[Project]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray rounded-top  lazy" data-src="/assets/images/covers/2023-conf-KDD-FedAPEN.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">FedAPEN: Personalized Cross-silo Federated Learning with Adaptability to Statistical Heterogeneity</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37089179203">Mingyu Zhao</a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37088391525">Xueqiang Yan</a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD)</i> 2023 </p>
                <p class="mt-0 mb-0 small text-muted">In cross-silo federated learning (FL), the data among clients are usually statistically heterogeneous (aka not independent and identically distributed, non-IID) due to diversified data sources, lowering the accuracy of FL. Although many personalized FL (PFL) approaches have been proposed to address this issue, they are only suitable for data with specific degrees of statistical heterogeneity. In the real world, the heterogeneity of data among clients is often immeasurable due to privacy concern, making the targeted selection of PFL approaches difficult. Besides, in cross-silo FL, clients are usually from different organizations, tending to hold architecturally different private models. In this work, we propose a novel FL framework, FedAPEN, which combines mutual learning and ensemble learning to take the advantages of private and shared global models while allowing heterogeneous models. Within FedAPEN, we propose two mechanisms to coordinate and promote model ensemble such that FedAPEN achieves excellent accuracy on various data distributions without prior knowledge of data heterogeneity, and thus, obtains the adaptability to data heterogeneity. We conduct extensive experiments on four real-world datasets, including: 1) Fashion MNIST, CIFAR-10, and CIFAR-100, each with ten different types and degrees of label distribution skew; and 2) eICU with feature distribution skew. The experiments demonstrate that FedAPEN almost obtains superior accuracy on data with varying types and degrees of heterogeneity compared with baselines.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://dl.acm.org/doi/abs/10.1145/3580305.3599344">[Paper]</a>
                    
                    
                    
                    <a target="_blank" href="https://github.com/zhenqincn/FedAPEN">[Project]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters border-bottom border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2023-jnl-MONET-data-plane.png" alt="6G Data Plane: A Novel Architecture Enabling Data Collaboration with Arbitrary Topology" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">6G Data Plane: A Novel Architecture Enabling Data Collaboration with Arbitrary Topology</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37088391525">Xueqiang Yan</a>, <span class="text-body">
            Lu Lu, </span><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37089179203">Mingyu Zhao</a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37089879242">Yan Xi</a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37404822200">Jianjun Wu</a>, <span class="text-body">
            Tao Sun, </span><span class="text-body">
            Nanxiang Shi</span>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>Mobile Networks and Applications (MONET)</i> 2023 </p>
            <p class="mt-0 mb-0 small text-muted">Although the fifth-generation wireless communication network (5G) has made much progress in improving the quality of user experience by providing large bandwidth transmission, it only provides the connectivity services between user equipments (UEs) and the network. With the sensing and intelligence are envisioned to become the native capability of the sixth-generation communication network (6G), there is an urgent need for a new network architecture enabling the “on-path-data-processing”, to make better leverage of distributed and ubiquitous computation resources and data. Thus, we propose a Data Plane in 6G network, which is independent of existing User Plane, aiming at constructing data pipelines based on various data service requirements. It systematically provides the collaboration of data among multiple network components with arbitrary topology with the support for on-path-data-processing. Based on this, we propose three data forwarding control protocols, guaranteeing the operation of Data Plane by providing data forwarding in any topology. Simulation experiments demonstrate the good scalability and efficiency of the three protocols in Data Plane.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://link.springer.com/article/10.1007/s11036-023-02093-y">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none border-bottom border-gray   lazy" data-src="/assets/images/covers/2023-jnl-MONET-data-plane.png">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">6G Data Plane: A Novel Architecture Enabling Data Collaboration with Arbitrary Topology</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37088391525">Xueqiang Yan</a>, <span class="text-body">
            Lu Lu, </span><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37089179203">Mingyu Zhao</a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37089879242">Yan Xi</a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37404822200">Jianjun Wu</a>, <span class="text-body">
            Tao Sun, </span><span class="text-body">
            Nanxiang Shi</span>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>Mobile Networks and Applications (MONET)</i> 2023 </p>
                <p class="mt-0 mb-0 small text-muted">Although the fifth-generation wireless communication network (5G) has made much progress in improving the quality of user experience by providing large bandwidth transmission, it only provides the connectivity services between user equipments (UEs) and the network. With the sensing and intelligence are envisioned to become the native capability of the sixth-generation communication network (6G), there is an urgent need for a new network architecture enabling the “on-path-data-processing”, to make better leverage of distributed and ubiquitous computation resources and data. Thus, we propose a Data Plane in 6G network, which is independent of existing User Plane, aiming at constructing data pipelines based on various data service requirements. It systematically provides the collaboration of data among multiple network components with arbitrary topology with the support for on-path-data-processing. Based on this, we propose three data forwarding control protocols, guaranteeing the operation of Data Plane by providing data forwarding in any topology. Simulation experiments demonstrate the good scalability and efficiency of the three protocols in Data Plane.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://link.springer.com/article/10.1007/s11036-023-02093-y">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2023-jnl-TSC-EUA.png" alt="ST-EUA: Spatio-Temporal Edge User Allocation With Task Decomposition" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">ST-EUA: Spatio-Temporal Edge User Allocation With Task Decomposition</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <span class="text-body">
            Ya Liu, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Jin Chen, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan<sup>*</sup></a>, <span class="text-body">
            Bofeng Chang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=O4PHMfQAAAAJ">Qiang He<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>IEEE Transactions on Services Computing (TSC)</i> 2023 </p>
            <p class="mt-0 mb-0 small text-muted">Recently, edge user allocation (EUA) problem has received much attentions. It aims to appropriately allocate edge users to their nearby edge servers. Existing EUA approaches suffer from a series of limitations. First, considering users’ service requests only as a whole, they neglect the fact that in many cases a service request may be partitioned into multiple tasks to be performed by different edge servers. Second, the impact of the spatial distance between edge users and servers on users’ quality of experience is not properly considered. Third, the temporal dynamics of users’ service requests has not been fully considered. To overcome these limitations systematically, this article focuses on the problem of spatio-temporal edge user allocation with task decomposition (ST-EUA). We first formulate the ST-EUA problem. Then, we transform ST-EUA problem as an optimization problem with multiple objectives and global constraints and prove its NP-hardness. To tackle the ST-EUA problem effectively and efficiently, we propose a novel genetic algorithm-based heuristic approach called GA-ST, aiming to maximize users’ overall QoE while minimizing the cost of task migration in different time slots. Extensive experiments are conducted on two widely-used real-world datasets to evaluate the performance of our approach. The results demonstrate that GA-ST significantly outperforms state-of-the-art approaches in finding approximate solutions in terms of the trade-off among multiple metrics.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://ieeexplore.ieee.org/document/9689946">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none  border-gray  rounded-bottom lazy" data-src="/assets/images/covers/2023-jnl-TSC-EUA.png">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">ST-EUA: Spatio-Temporal Edge User Allocation With Task Decomposition</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <span class="text-body">
            Ya Liu, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <span class="text-body">
            Jin Chen, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan<sup>*</sup></a>, <span class="text-body">
            Bofeng Chang, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=O4PHMfQAAAAJ">Qiang He<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>IEEE Transactions on Services Computing (TSC)</i> 2023 </p>
                <p class="mt-0 mb-0 small text-muted">Recently, edge user allocation (EUA) problem has received much attentions. It aims to appropriately allocate edge users to their nearby edge servers. Existing EUA approaches suffer from a series of limitations. First, considering users’ service requests only as a whole, they neglect the fact that in many cases a service request may be partitioned into multiple tasks to be performed by different edge servers. Second, the impact of the spatial distance between edge users and servers on users’ quality of experience is not properly considered. Third, the temporal dynamics of users’ service requests has not been fully considered. To overcome these limitations systematically, this article focuses on the problem of spatio-temporal edge user allocation with task decomposition (ST-EUA). We first formulate the ST-EUA problem. Then, we transform ST-EUA problem as an optimization problem with multiple objectives and global constraints and prove its NP-hardness. To tackle the ST-EUA problem effectively and efficiently, we propose a novel genetic algorithm-based heuristic approach called GA-ST, aiming to maximize users’ overall QoE while minimizing the cost of task migration in different time slots. Extensive experiments are conducted on two widely-used real-world datasets to evaluate the performance of our approach. The results demonstrate that GA-ST significantly outperforms state-of-the-art approaches in finding approximate solutions in terms of the trade-off among multiple metrics.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://ieeexplore.ieee.org/document/9689946">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
        
        <h2 class="pt-4" id="year-2022">2022</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-sm">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2022-jnl-TSC-DeepWSC.svg" alt="DeepWSC: Clustering Web Services via Integrating Service Composability into Deep Semantic Features" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">DeepWSC: Clustering Web Services via Integrating Service Composability into Deep Semantic Features</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=O4PHMfQAAAAJ">Qiang He</a>, <span class="text-body">
            Pengwei Wang, </span><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37279403500">Bofeng Zhang</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>IEEE Transactions on Services Computing (TSC)</i> 2022 </p>
            <p class="mt-0 mb-0 small text-muted">With an growing number of web services available on the Internet, an increasing burden is imposed on the use and management of service repository. Service clustering has been employed to facilitate a wide range of service-oriented tasks, such as service discovery, selection, composition and recommendation. Conventional approaches have been proposed to cluster web services by using explicit features, including syntactic features contained in service descriptions or semantic features extracted by probabilistic topic models. However, service implicit features are ignored and have yet to be properly explored and leveraged. To this end, we propose a novel heuristics-based framework DeepWSC for web service clustering. It integrates deep semantic features extracted from service descriptions by an improved recurrent convolutional neural network and service composability features obtained from service invocation relationships by a signed graph convolutional network, to jointly generate integrated implicit features for web service clustering. Extensive experiments are conducted on 8,459 real-world web services. The experiment results demonstrate that DeepWSC outperforms state-of-the-art approaches for web service clustering in terms of multiple evaluation metrics.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9204770/">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none  border-gray rounded-top rounded-bottom lazy" data-src="/assets/images/covers/2022-jnl-TSC-DeepWSC.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">DeepWSC: Clustering Web Services via Integrating Service Composability into Deep Semantic Features</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=O4PHMfQAAAAJ">Qiang He</a>, <span class="text-body">
            Pengwei Wang, </span><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37279403500">Bofeng Zhang</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>IEEE Transactions on Services Computing (TSC)</i> 2022 </p>
                <p class="mt-0 mb-0 small text-muted">With an growing number of web services available on the Internet, an increasing burden is imposed on the use and management of service repository. Service clustering has been employed to facilitate a wide range of service-oriented tasks, such as service discovery, selection, composition and recommendation. Conventional approaches have been proposed to cluster web services by using explicit features, including syntactic features contained in service descriptions or semantic features extracted by probabilistic topic models. However, service implicit features are ignored and have yet to be properly explored and leveraged. To this end, we propose a novel heuristics-based framework DeepWSC for web service clustering. It integrates deep semantic features extracted from service descriptions by an improved recurrent convolutional neural network and service composability features obtained from service invocation relationships by a signed graph convolutional network, to jointly generate integrated implicit features for web service clustering. Extensive experiments are conducted on 8,459 real-world web services. The experiment results demonstrate that DeepWSC outperforms state-of-the-art approaches for web service clustering in terms of multiple evaluation metrics.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://ieeexplore.ieee.org/abstract/document/9204770/">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
        
        <h2 class="pt-4" id="year-2021">2021</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-sm">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2021-jnl-KBS.svg" alt="Towards the optimality of service instance selection in mobile edge computing" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">Towards the optimality of service instance selection in mobile edge computing</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng</a>, <span class="text-body">
            Kuan-Ching Li, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37279403500">Bofeng Zhang<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i> 2021 </p>
            <p class="mt-0 mb-0 small text-muted">Mobile edge computing (MEC) has been proposed to significantly reduce the response time of service invocations for end users. In MEC environment, a service provider can create multiple instances from a service and deploy them to different hired edge servers, where the deployed instances can be selected and invoked to decrease the network latency by nearby users. However, service instance selection in MEC is a challenging research problem from threefold aspects. First, the limitations of an edge server in terms of computation capacity and coverage range result in serving for only a certain number of users at the same time. Second, due to variable geographical locations from user mobility paths in MEC, the mobility of edge users is highly related to data transmission rate and affects the delay of service invocations. Furthermore, when many users in an edge server covered region request the same service instance at the same time, they interfere with each other and may reduce the experience of service invocations if there is no effective strategy to distribute these requests to appropriate instances deployed on different edge servers. To improve the user experience on service invocations with a lower response time, we take the above three factors into account and model the service instance selection problem (SISP) in MEC as an optimization problem, and propose a novel genetic algorithm-based approach with a response time-aware mutation operation with normalization for service instance selection called GASISMEC to find approximately optimal solution. Extensive experiments are conducted on two widely-used real-world datasets. The results demonstrate that our approach significantly outperforms the six baseline competing approaches.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://www.sciencedirect.com/science/article/abs/pii/S0950705121000940">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none  border-gray rounded-top rounded-bottom lazy" data-src="/assets/images/covers/2021-jnl-KBS.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">Towards the optimality of service instance selection in mobile edge computing</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=txbuN0YAAAAJ">Shuiguang Deng</a>, <span class="text-body">
            Kuan-Ching Li, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan<sup>*</sup></a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37279403500">Bofeng Zhang<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>IEEE Transactions on Pattern Analysis and Machine Intelligence</i> 2021 </p>
                <p class="mt-0 mb-0 small text-muted">Mobile edge computing (MEC) has been proposed to significantly reduce the response time of service invocations for end users. In MEC environment, a service provider can create multiple instances from a service and deploy them to different hired edge servers, where the deployed instances can be selected and invoked to decrease the network latency by nearby users. However, service instance selection in MEC is a challenging research problem from threefold aspects. First, the limitations of an edge server in terms of computation capacity and coverage range result in serving for only a certain number of users at the same time. Second, due to variable geographical locations from user mobility paths in MEC, the mobility of edge users is highly related to data transmission rate and affects the delay of service invocations. Furthermore, when many users in an edge server covered region request the same service instance at the same time, they interfere with each other and may reduce the experience of service invocations if there is no effective strategy to distribute these requests to appropriate instances deployed on different edge servers. To improve the user experience on service invocations with a lower response time, we take the above three factors into account and model the service instance selection problem (SISP) in MEC as an optimization problem, and propose a novel genetic algorithm-based approach with a response time-aware mutation operation with normalization for service instance selection called GASISMEC to find approximately optimal solution. Extensive experiments are conducted on two widely-used real-world datasets. The results demonstrate that our approach significantly outperforms the six baseline competing approaches.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://www.sciencedirect.com/science/article/abs/pii/S0950705121000940">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
        
        <h2 class="pt-4" id="year-2020">2020</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-sm">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2020-conf-ICSOC-EUA.png" alt="TD-EUA: Task-Decomposable Edge User Allocation with QoE Optimization" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">TD-EUA: Task-Decomposable Edge User Allocation with QoE Optimization</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <span class="text-body">
            Ya Liu, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin<sup>*</sup></strong></a>, <span class="text-body">
            Jin Chen, </span><span class="text-body">
            Zhiwei Xu, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan</a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37279403500">Bofeng Zhang</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=O4PHMfQAAAAJ">Qiang He<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>International Conference on Service-Oriented Computing (ICSOC)</i> 2020 </p>
            <p class="mt-0 mb-0 small text-muted">The edge user allocation (EUA) problem has attracted a lot of attention recently. EUA aims at allocating edge users to nearby edge servers strategically to ensure low-latency network connection. Existing approaches assume that a users’ request can only be served by an individual edge server or cannot be served at all. They neglect the fact that a user’s request may be decomposable and partitioned into multiple tasks to be performed by different edge servers. To tackle this new task-decomposable edge user allocation (TD-EUA) problem, we model it as an optimization problem. Two novel approaches named TD-EUA-O and TD-EUA-H are proposed, one for finding the optimal solution based on Integer Linear Programming that maximizes users’ overall Quality of Experience (QoE), and the other for efficiently finding a sub-optimal solution in large-scale EUA scenarios. Extensive experiments based on a widely-used real-world dataset are conducted to evaluate the effectiveness and efficiency of our approaches. The results demonstrate that our approaches significantly outperform the baseline and the state-of-the-art approach.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://link.springer.com/chapter/10.1007/978-3-030-65310-1_17">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none  border-gray rounded-top rounded-bottom lazy" data-src="/assets/images/covers/2020-conf-ICSOC-EUA.png">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">TD-EUA: Task-Decomposable Edge User Allocation with QoE Optimization</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <span class="text-body">
            Ya Liu, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin<sup>*</sup></strong></a>, <span class="text-body">
            Jin Chen, </span><span class="text-body">
            Zhiwei Xu, </span><a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan</a>, <a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37279403500">Bofeng Zhang</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=O4PHMfQAAAAJ">Qiang He<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>International Conference on Service-Oriented Computing (ICSOC)</i> 2020 </p>
                <p class="mt-0 mb-0 small text-muted">The edge user allocation (EUA) problem has attracted a lot of attention recently. EUA aims at allocating edge users to nearby edge servers strategically to ensure low-latency network connection. Existing approaches assume that a users’ request can only be served by an individual edge server or cannot be served at all. They neglect the fact that a user’s request may be decomposable and partitioned into multiple tasks to be performed by different edge servers. To tackle this new task-decomposable edge user allocation (TD-EUA) problem, we model it as an optimization problem. Two novel approaches named TD-EUA-O and TD-EUA-H are proposed, one for finding the optimal solution based on Integer Linear Programming that maximizes users’ overall Quality of Experience (QoE), and the other for efficiently finding a sub-optimal solution in large-scale EUA scenarios. Extensive experiments based on a widely-used real-world dataset are conducted to evaluate the effectiveness and efficiency of our approaches. The results demonstrate that our approaches significantly outperform the baseline and the state-of-the-art approach.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://link.springer.com/chapter/10.1007/978-3-030-65310-1_17">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
        
        <h2 class="pt-4" id="year-2019">2019</h2>
        <div class="my-0 p-0 bg-white shadow-sm rounded-sm">
            
                
<div class="d-none d-md-block">
    <div class="row no-gutters  border-gray">
        <div class="col-md-3 col-xl-2 mb-md-0 p-md-3"><img data-src="/assets/images/covers/2019-conf-ICWS-DeepWSC.svg" alt="DeepWSC: A Novel Framework with Deep Neural Network for Web Service Clustering" class="lazy w-100 rounded-sm" src="/assets/images/empty_300x200.png"></div>
        <div class="col-md-9 col-xl-10 p-3 pl-md-0">
            <h5 class="mt-0 mb-1 font-weight-normal">DeepWSC: A Novel Framework with Deep Neural Network for Web Service Clustering</h5>
            <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=O4PHMfQAAAAJ">Qiang He</a>, <span class="text-body">
            Pengwei Wang, </span><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37279403500">Bofeng Zhang</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
            <p class="mt-0 mb-0 small"><i>IEEE International Conference on Web Services (ICWS)</i> 2019 </p>
            <p class="mt-0 mb-0 small text-muted">Correlative approaches have attempted to cluster web services based on either the explicit information contained in service descriptions or functionality semantic features extracted by probabilistic topic models. However, the implicit contextual information of service descriptions is ignored and has yet to be properly explored and leveraged. To this end, we propose a novel framework with deep neural network, called DeepWSC, which combines the advantages of recurrent neural network and convolutional neural network to cluster web services through automatic feature extraction. The experimental results demonstrate that DeepWSC outperforms state-of-the-art approaches for web service clustering in terms of multiple evaluation metrics.</p>
            
            <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                
                
                <a target="_blank" href="https://ieeexplore.ieee.org/document/8818454">[Paper]</a>
                
                
            </p>

        </div>
    </div>
</div>

<div class="row no-gutters d-md-none  border-gray rounded-top rounded-bottom lazy" data-src="/assets/images/covers/2019-conf-ICWS-DeepWSC.svg">
    <div class="w-100" style="background-color: rgba(255,255,255,0.9);">
        <div class="d-flex align-items-start flex-column py-3 px-4">
            <div class="mb-auto"></div>
            <div>
                <h5 class="mt-0 mb-1 font-weight-normal">DeepWSC: A Novel Framework with Deep Neural Network for Web Service Clustering</h5>
                <p class="mt-0 mb-0 small"><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37605660000">Guobing Zou</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=yRy86mQAAAAJ"><strong>Zhen Qin</strong></a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=O4PHMfQAAAAJ">Qiang He</a>, <span class="text-body">
            Pengwei Wang, </span><a class="text-body" target="_blank" href="https://ieeexplore.ieee.org/author/37279403500">Bofeng Zhang</a>, <a class="text-body" target="_blank" href="https://scholar.google.com/citations?user=IbReBrYAAAAJ">Yanglan Gan<sup>*</sup></a>
<mark>(<sup>*</sup> <i> corresponding author</i>)</mark></p>
                <p class="mt-0 mb-0 small"><i>IEEE International Conference on Web Services (ICWS)</i> 2019 </p>
                <p class="mt-0 mb-0 small text-muted">Correlative approaches have attempted to cluster web services based on either the explicit information contained in service descriptions or functionality semantic features extracted by probabilistic topic models. However, the implicit contextual information of service descriptions is ignored and has yet to be properly explored and leveraged. To this end, we propose a novel framework with deep neural network, called DeepWSC, which combines the advantages of recurrent neural network and convolutional neural network to cluster web services through automatic feature extraction. The experimental results demonstrate that DeepWSC outperforms state-of-the-art approaches for web service clustering in terms of multiple evaluation metrics.</p>
                
                <p class="small pb-0 mb-0 lh-125 text-muted abstract-links">
                    
                    
                    <a target="_blank" href="https://ieeexplore.ieee.org/document/8818454">[Paper]</a>
                    
                    
                </p>
            </div>
        </div>
    </div>

</div>
            
        </div>
        
    </div>

    <div class="col-2 d-none d-lg-block">
        <div id="navbar-year" class="nav nav-pills flex-column sticky-top" style="top: 80px">
            
            <a class="nav-link d-block" href="#year-2025">2025</a>
            
            <a class="nav-link d-block" href="#year-2024">2024</a>
            
            <a class="nav-link d-block" href="#year-2023">2023</a>
            
            <a class="nav-link d-block" href="#year-2022">2022</a>
            
            <a class="nav-link d-block" href="#year-2021">2021</a>
            
            <a class="nav-link d-block" href="#year-2020">2020</a>
            
            <a class="nav-link d-block" href="#year-2019">2019</a>
            
        </div>
    </div>

</div>

    </div>
    <footer class="footer">
    <div class="container-lg">
        <div class="row my-3">
            <div class="col-6">
                <div class="text-muted">
                    <i>Last updated: Aug 2025</i>
                </div>
            </div>
            <div class="col-6">
                <div class="text-right text-muted">
                    
                </div>
            </div>
        </div>
    </div>
</footer>


    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery.lazy/1.7.9/jquery.lazy.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.6.0/js/bootstrap.min.js" integrity="sha512-XKa9Hemdy1Ui3KSGgJdgMyYlUg1gM+QhL6cnlyTe2qzMCYm4nAZ1PsVerQzTTXzonUR+dmswHqgJPuwCq1MaAg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/github-buttons/2.14.2/buttons.min.js" integrity="sha512-OYwZx04hKFeFNYrWxIyo3atgGpb+cxU0ENWBZs72X7T9U+NoHPM1ftUn/Mfw7dRDXrqWA6M1wBg6z6fGE32aeA==" crossorigin="anonymous"></script>
    <script src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
    <script src="https://unpkg.com/imagesloaded@5/imagesloaded.pkgd.min.js"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/katex.min.js" integrity="sha384-7zkQWkzuo3B5mTepMUcHkMB5jZaolc2xDwL6VFqjFALcbeS9Ggm/Yr2r3Dy4lfFg" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.11/dist/contrib/auto-render.min.js" integrity="sha384-43gviWU0YVjaDtb/GhzOouOXtZMP/7XUzwPTstBeZFe/+rCMvRwr4yROQP43s0Xk" crossorigin="anonymous"></script>
    <script>
        document.addEventListener("DOMContentLoaded", function() {
            renderMathInElement(document.body, {
              delimiters: [
                  {left: '$$', right: '$$', display: true},
                  {left: '$', right: '$', display: false}
              ],
              throwOnError : false
            });
        });
    </script>
    <script src="/assets/js/common.js"></script>
    <script src="/assets/js/bubble_visual_hash.js"></script>
</body>
</html>
